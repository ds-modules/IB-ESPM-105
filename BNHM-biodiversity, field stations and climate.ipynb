{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESPM / IB 105\n",
    "The goal of this notebook is to access and integrate diverse data sets to visualize correlations and discover patterns to address questions of speciesâ€™ responses to environmental change. We will use programmatic tools to show how to use Berkeley resources such as the biodiversity data from biocollections and online databases, field stations, climate models, and other environmental data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this code first. This imports all the libraries, which are sets of reusable functions and resources that someone else wrote. Since writing all the code for sending requests to a server is out of the scope of this class, we need to use a library that someone else built to do that for us! You can google each library to see what its purpose is. \n",
    "\n",
    "Another term you will see is API (application programming interface), which refers to the functions/methods in a library that you can call to ask it to do things for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from descartes import PolygonPatch\n",
    "import matplotlib as mpl\n",
    "from matplotlib.collections import PatchCollection\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from shapely import geometry as sg, wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will demonstrate the intersection of collection data, field station boundaries and future climate datasets. Essentially, we will be parsing a lot of data and trying to display it in a meaningful manner. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a matplotlib style. See `plt.style.available` for all the available styles. For now, we will use Seaborn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [GBIF Web API](http://www.gbif.org/developer/summary) utilizes pagination to split up the returned JSON records, so we need to request each successive page to gather all the results. This helper class will handle that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GBIFRequest(object):\n",
    "    \"\"\"GBIF requests with pagination handling.\"\"\"\n",
    "    url = 'http://api.gbif.org/v1/occurrence/search'\n",
    "\n",
    "    def fetch(self, params):\n",
    "        resp = requests.get(self.url, params=params)\n",
    "        return resp.json()\n",
    "\n",
    "    def get_pages(self, params):\n",
    "        params = dict({'limit': 100, 'offset': 0}, **params)\n",
    "        data = {'endOfRecords': False}\n",
    "        while not data['endOfRecords']:\n",
    "            data = self.fetch(params)\n",
    "            params['offset'] += params['limit']\n",
    "            yield data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can request the available occurrence records for a particular species and plot their locations. Here we're going to make a request for the species whose scientific name is 'Argia agrioides', also known as the [California dancer](https://www.google.com/search?q=Argia+agrioides&rlz=1C1CHBF_enUS734US734&source=lnms&tbm=isch&sa=X&ved=0ahUKEwji9t29kNTWAhVBymMKHWJ-ANcQ_AUICygC&biw=1536&bih=694). We're going to plot their locations and display other data results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "req = GBIFRequest()\n",
    "params = {'scientificName': 'Argia agrioides'}\n",
    "pages = req.get_pages(params)\n",
    "# Filter all the returned records for valid locations.\n",
    "records = [rec for page in pages for rec in page['results']\n",
    "           if rec.get('decimalLatitude')]\n",
    "# Make a list of coordinate pairs for plotting.\n",
    "coords = [(r['decimalLongitude'], r['decimalLatitude']) for r in records]\n",
    "xs, ys = zip(*coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a plot of species' locations below.\n",
    "plt.plot(xs, ys, 'ro', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the reserves, we will need to send a request to GeoJSON, which is a format for encoding a variety of geographic data structures. With this code, we can request GeoJSON for all reserves and plot ocurrences of the species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the url where are data is located \n",
    "url = 'https://ecoengine.berkeley.edu/api/layers/reserves/features/'\n",
    "# Make a request, which receives data from this url. Then iterate throuh each feature so we can collect data about them.\n",
    "reserves = requests.get(url, params={'page_size': 30}).json()\n",
    "geoms = {feat['properties']['name']: sg.asShape(feat['geometry']) for feat in reserves['features']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buffer the reserves so we can view them at a regional scale.\n",
    "patches = [PolygonPatch(geom.buffer(0.25)) for geom in geoms.values()]\n",
    "fig, ax = plt.subplots()\n",
    "colors = 100 * np.random.rand(len(patches))\n",
    "p = PatchCollection(patches, cmap='tab10', alpha=0.4)\n",
    "p.set_array(np.array(colors))\n",
    "ax.add_collection(p)\n",
    "ax.autoscale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and zoom in to the Santa Cruz Island Reserve where we have a single occurrence, and plot it similarly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data about what we want to graph.\n",
    "fig, ax = plt.subplots()\n",
    "g = geoms['Santa Cruz Island Reserve']\n",
    "poly = PolygonPatch(g)\n",
    "ax.add_patch(poly)\n",
    "# Plot a graph representing the Santa Cruz Island Reserve using the data we've accumulated in these variables.\n",
    "ax.plot(xs, ys, 'ro', clip_path=poly)\n",
    "xmin, ymin, xmax, ymax = g.bounds\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way, we can parse the WKT geometry for Blodgett, Hopland, and Sagehen stations and plot them individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station_urls = {\n",
    "    'Blodgett': 'https://raw.githubusercontent.com/BNHM/spatial-layers/master/wkt/BlodgettForestResearchStation.wkt',\n",
    "    'Hopland': 'https://raw.githubusercontent.com/BNHM/spatial-layers/master/wkt/HoplandREC.wkt',\n",
    "    'Sagehen': 'https://raw.githubusercontent.com/BNHM/spatial-layers/master/wkt/SagehenCreekFieldStation.wkt'\n",
    "}\n",
    "stn_features = [{'id': name, 'geometry': wkt.loads(requests.get(url).text)}\n",
    "                for name, url in station_urls.items()]\n",
    "# Reduce geometric complexity, we need smaller geometry serializations to circumvent \n",
    "# URL length restrictions.\n",
    "tol = .0001\n",
    "for feat in stn_features:\n",
    "    feat['geometry'] = feat['geometry'].buffer(tol).simplify(tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, len(stn_features))\n",
    "f.set_size_inches((12, 6))\n",
    "\n",
    "# Title our graphs.\n",
    "for ax, feat in zip(axes, stn_features):\n",
    "    ax.add_patch(PolygonPatch(feat['geometry']))\n",
    "    ax.set_title(feat['id'])\n",
    "    ax.autoscale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will use the [Cal-Adapt](http://api.cal-adapt.org/api/) web API to access a remote raster data source and preview a rendered image. In this case, the data source contains images of locations and temperature information corresponding to each one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://api.cal-adapt.org/api/series/tasmax_year_CanESM2_rcp85/rasters/'\n",
    "json = requests.get(url).json()\n",
    "tifurl = json['results'][0]['image']\n",
    "title = json['results'][0]['slug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import greenwich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with greenwich.open(tifurl) as r:\n",
    "    arr = r.masked_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to visualize the resulting masked array. The array values are maximum temperature in Kelvin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Matplotlib to create a color-coded plot of the resulting masked array:\n",
    "plt.imshow(arr, cmap='spectral')\n",
    "plt.title(title)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Matplotlib to plot a histogram (arr should be un-masked here)\n",
    "\n",
    "h = plt.hist(arr.compressed(), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we look closer at the Cal-Adapt API, the following will ease working with time series raster data. It will request an entire time series for any geometry and return a Pandas `DataFrame` object. This will make displaying the data much easier with Pandas' built in methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_fahren(val):\n",
    "    return (val - 273.15) * 9 / 5 + 32\n",
    "\n",
    "\n",
    "class CalAdaptRequest(object):\n",
    "    series_url = 'http://api.cal-adapt.org/api/series/'\n",
    "\n",
    "    def __init__(self, slug=None):\n",
    "        self.slug = slug or 'tasmax_year_CanESM2_rcp85'\n",
    "        self.params = {'pagesize': 94}\n",
    "    \n",
    "    def concat_features(self, features, field='id'):\n",
    "        lst = []\n",
    "        for feat in features:\n",
    "            json = self.series(geom=feat['geometry'])\n",
    "            series = self.to_frame(json)['image']\n",
    "            if series.any():\n",
    "                series.name = feat[field]\n",
    "                lst.append(series)\n",
    "        return pd.concat(lst, axis=1)\n",
    "    \n",
    "    def list_series_slugs(self):\n",
    "        json = requests.get(self.series_url, params=self.params).json()\n",
    "        return [row['slug'] for row in json['results']]\n",
    "\n",
    "    def series(self, geom=None):\n",
    "        url = '%s%s/rasters/' % (self.series_url, self.slug)\n",
    "        if geom:\n",
    "            params = dict(self.params, g=geom.wkt)\n",
    "            if isinstance(geom, (sg.Polygon, sg.MultiPolygon)):\n",
    "                params['stat'] = 'mean'\n",
    "        return requests.get(url, params=params).json()\n",
    "    \n",
    "    def series(self, geom=None, dates=None):\n",
    "        if dates:\n",
    "            url = os.path.join(self.series_url, self.slug, *dates)\n",
    "        else:\n",
    "            url = os.path.join(self.series_url, self.slug, 'rasters/')\n",
    "        if geom:\n",
    "            params = dict(self.params, g=geom.wkt)\n",
    "            if isinstance(geom, (sg.Polygon, sg.MultiPolygon)):\n",
    "                params['stat'] = 'mean'\n",
    "        return requests.get(url, params=params).json()\n",
    "    \n",
    "    def to_frame(self, json):\n",
    "        df = pd.DataFrame.from_records(json['results'])\n",
    "        df['image'] = to_fahren(pd.to_numeric(df['image']))\n",
    "        df['event'] = pd.to_datetime(df['event'], format='%Y-%m-%d')\n",
    "        df.set_index('event', inplace=True)\n",
    "        return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating Pandas dataframe by combining requested time series with records_g\n",
    "req = CalAdaptRequest()\n",
    "records_g = [dict(rec, geometry=sg.Point(rec['decimalLongitude'], rec['decimalLatitude']))\n",
    "             for rec in records]\n",
    "df = req.concat_features(records_g, 'gbifID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,:9].plot()\n",
    "plt.title('Argia agrioides - %s' % req.slug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can map the projected means for occurrence locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax_means = df.mean(axis=0)\n",
    "# Filter GBIF records where we have climate data.\n",
    "records_rvals = [rec for rec in records_g if rec['gbifID'] in tmax_means.index]\n",
    "coords = [(r['decimalLongitude'], r['decimalLatitude']) for r in records_rvals]\n",
    "xs2, ys2 = zip(*coords)\n",
    "#plt.scatter(xs2, ys2, c=tmax_means, cmap='viridis', alpha=0.5)\n",
    "norm = mpl.colors.Normalize()\n",
    "size = np.pi * (15 * norm(tmax_means)) ** 2 \n",
    "plt.scatter(xs2, ys2, c=tmax_means, s=size, cmap='viridis', alpha=0.5)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(12, 6))\n",
    "df.iloc[:,:7].plot.box()\n",
    "plt.title('Argia agrioides - %s' % req.slug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at minimum temperatures now, here are the temperature distributions by decade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "names = ('tasmin_year_CanESM2_rcp45', 'tasmin_year_CanESM2_rcp85')\n",
    "for name in names:\n",
    "    req = CalAdaptRequest(name)\n",
    "    dfs.append(req.concat_features(records_g, 'gbifID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in zip(names, dfs):\n",
    "    t = df.resample('10A').mean().transpose()\n",
    "    t.columns = t.columns.year\n",
    "    t.plot.box()\n",
    "    plt.title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make plots for historical and projected temperatures at three station locations. Once again, Pandas gives us a lot of functionality in displaying our data beautifully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfstns_lst = []\n",
    "names = ('tasmax_year_CanESM2_historical', 'tasmax_year_CanESM2_rcp85')\n",
    "# Iterate through each name and make requests using the CalAdapt API. We can also use Pandas to display this data efficiently.\n",
    "for name in names:\n",
    "    req = CalAdaptRequest(name)\n",
    "    d = req.concat_features(stn_features)\n",
    "    dfstns_lst.append(d)\n",
    "    #d.plot()\n",
    "    #plt.title(name)\n",
    "dfstns = pd.concat(dfstns_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfstns.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfstns.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decadal average and difference from 20 years prior.\n",
    "dfstns.resample('10A').mean().diff(periods=2).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfstns.resample('10A').mean().diff().plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
