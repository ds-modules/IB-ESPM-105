{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"anaconda-cloud":{}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Run the cell below to setup the notebook (_shift+return in cell to run_ or Press Run button in the menu)\nDo you see a number in the left margin of the cell below? If so, click on _Kernel->Restart and Clear Output_","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install --no-cache-dir shapely\n!pip install -U folium\n\nimport os\nimport time\nimport folium\nfrom datetime import datetime\nfrom shapely.geometry import Point, mapping\nfrom shapely.geometry.polygon import Polygon\nimport matplotlib as mpl\nfrom matplotlib.collections import PatchCollection\nimport matplotlib.pyplot as plot\nimport numpy as np\nimport pandas as pd\nimport requests\nfrom datascience import *\nfrom shapely import geometry as sg, wkt\nfrom scripts.espm_module import *\nimport json\nimport random\nfrom IPython.display import display, HTML\nimport ipywidgets as widgets\nimport urllib3\n%matplotlib inline\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ESPM / IB 105 Natural History Museums and Data Science\n\nThe goal of this notebook is to access and integrate diverse data sets to visualize correlations and discover patterns to address questions of species’ responses to environmental change. We will use programmatic tools to show how to use Berkeley resources such as the biodiversity data from biocollections and online databases, field stations, climate models, and other environmental data.\n\nBefore we begin analyzing and visualizing biodiversity data, this introductory notebook will help familiarize you with the basics of programming in Python.\n\n## Table of Contents\n\n0 - [Jupyter Notebooks](#jupyter)\n    \n1 - [Python Basics](#basics)\n\n2 - [GBIF API](#gbif)\n\n3 - [Comparing California Oak Species](#oak)","metadata":{}},{"cell_type":"markdown","source":"# Part 0: Our Computing Environment, Jupyter notebooks  <a id='jupyter'></a>\nThis webpage is called a Jupyter notebook. A notebook is a place to write programs and view their results. \n\n### Text cells\nIn a notebook, each rectangle containing text or code is called a *cell*.\n\nText cells (like this one) can be edited by double-clicking on them. They're written in a simple format called [Markdown](http://daringfireball.net/projects/markdown/syntax) to add formatting and section headings.  You don't need to learn Markdown, but you might want to.\n\nAfter you edit a text cell, click the \"run cell\" button at the top that looks like ▶| to confirm any changes. (Try not to delete the instructions of the lab.)","metadata":{}},{"cell_type":"markdown","source":"### Code cells\nOther cells contain code in the Python 3 language. Running a code cell will execute all of the code it contains.\n\nTo run the code in a code cell, first click on that cell to activate it.  It'll be highlighted with a little green or blue rectangle.  Next, either press ▶| or hold down the `shift` key and press `return` or `enter`.\n\nTry running this cell:","metadata":{}},{"cell_type":"code","source":"print(\"Hello, World!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"And this one:","metadata":{}},{"cell_type":"code","source":"print(\"\\N{WAVING HAND SIGN}, \\N{EARTH GLOBE ASIA-AUSTRALIA}!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Part 1: Python basics <a id='basics'></a>\nBefore getting into the more high level analyses we will do on the GBIF and Cal-Adapt data, we need to cover a few of the foundational elements of programming in Python.\n\n#### A. Expressions\nThe departure point for all programming is the concept of the __expression__. An expression is a combination of variables, operators, and other Python elements that the language interprets and acts upon. Expressions act as a set of instructions to be fed through the interpreter, with the goal of generating specific outcomes. See below for some examples of basic expressions. Keep in mind that most of these just map to your understanding of mathematical expressions:","metadata":{}},{"cell_type":"code","source":"'Romeo' + ' and Juliet'\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"You will notice that only the last line in a cell gets printed out. If you want to see the values of previous expressions, you need to call the `print` function on that expression. Functions use parenthesis around their parameters, just like in math!","metadata":{}},{"cell_type":"code","source":"print(2 + 2)\n\nprint('you' + ' and I')\n\nprint(12 ** 2)\n\nprint(6 + 4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### B. Variables\nIn the example below, `a` and `b` are Python objects known as __variables__. We are giving an object (in this case, an `integer` and a `float`, two Python data types) a name that we can store for later use. To use that value, we can simply type the name that we stored the value as. Variables are stored within the notebook's environment, meaning stored variable values carry over from cell to cell.","metadata":{}},{"cell_type":"code","source":"a = 4\nb = 10/5","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Notice that when you create a variable, unlike what you previously saw with the expressions, it does not print anything out.\n\nWe can continue to perform mathematical operations on these variables, which are now placeholders for what we've assigned:","metadata":{}},{"cell_type":"code","source":"print(a + b)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### C. Lists\nThe following few cells will introduce the concept of __lists__.\n\nA list is an ordered collection of objects. They allow us to store and access groups of variables and other objects for easy access and analysis. Check out this [documentation](https://www.tutorialspoint.com/python/python_lists.htm) for an in-depth look at the capabilities of lists.\n\nTo initialize a list, you use brackets. Putting objects separated by commas in between the brackets will add them to the list. ","metadata":{}},{"cell_type":"code","source":"# an empty list\nlst = []\nprint(lst)\n\n# reassigning our empty list to a new list\nlst = [1, 3, 6, 'lists', 'are' 'fun', 4]\nprint(lst)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To access a value in the list, put the index of the item you wish to access in brackets following the variable that stores the list. Lists in Python are zero-indexed, so the indicies for `lst` are 0, 1, 2, 3, 4, 5, and 6.","metadata":{}},{"cell_type":"code","source":"# Elements are selected like this:\nexample = lst[2]\n\n# The above line selects the 3rd element of lst (list indices are 0-offset) and sets it to a variable named example.\nprint(example)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### D. Dictionaries\n\nDictionaries are `key`-`value` pairs. Just like a word dictionary, you have a key that will index a specific definition.","metadata":{}},{"cell_type":"code","source":"my_dict = {'python': 'a large heavy-bodied nonvenomous constrictor snake occurring throughout the Old World tropics.'}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can get a `value` back out by indexing the `key`:","metadata":{}},{"cell_type":"code","source":"my_dict['python']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"But like real dictionaries, there can be more than one definition. You can keep a `list`, or even another dictionary within a specific `key`:","metadata":{}},{"cell_type":"code","source":"my_dict = {'python': ['a large heavy-bodied nonvenomous constrictor snake occurring throughout the Old World tropics.',\n                      'a high-level general-purpose programming language.']}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can index the `list` after the `key`:","metadata":{}},{"cell_type":"code","source":"my_dict['python'][0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"my_dict['python'][1]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n# Part 2: GBIF API<a id='gbif'></a>\n\nThe Global Biodiversity Information Facility has created an API that we can use to get data about different species at the [GBIF Web API](http://www.gbif.org/developer/summary).\n\nYou can think of a Web API call as a fancy URL, what do you think the end of this URL means:\n\nhttp://api.gbif.org/v1/occurrence/search?year=1800,1899\n\nIf you're guessing that it limits the search to the years 1800-1899, you're right! Go ahead and click the URL above. You should see something like this:\n\n```\n{\"offset\":0,\"limit\":20,\"endOfRecords\":false,\"count\":5711947,\"results\":[{\"key\":14339704,\"datasetKey\":\"857aa892-f762-11e1-a439-00145eb45e9a\",\"publishingOrgKey\":\"6bcc0290-6e76-11db-bcd5-b8a03c50a862\",\"publishingCountry\":\"FR\",\"protocol\":\"BIOCASE\",\"lastCrawled\":\"2013-09-07T07:06:34.000+0000\",\"crawlId\":1,\"extensions\":{},\"basisOfRecord\":\"OBSERVATION\",\"taxonKey\":2809968,\"kingdomKey\":6,\"phylumKey\":7707728,\"classKey\":196,\"orderKey\":1169,\"familyKey\":7689,\"genusKey\":2849312,\"speciesKey\":2809968,\"scientificName\":\"Orchis militaris L.\",\"kingdom\":\"Plantae\",\"phylum\":\"Tracheophyta\",\"order\":\"Asparagales\",\"family\":\"Orchidaceae\",\"genus\":\"Orchis\",\"species\":\"Orchis \n```\n\nIt might look like a mess, but it's not! This is actually very structured data, and can easily be put into a table like format, though often programmers don't do this because it's just as easy to keep it as is.\n\nYou might be able to pick out the curly braces `{` and think this is a dictionary. You'd be right, except in this format we call it [JSON](https://en.wikipedia.org/wiki/JSON).\n\n---\n\n## *Argia arioides*\n\n![argia arioides](https://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/Argia_agrioides-Male-1.jpg/220px-Argia_agrioides-Male-1.jpg)\n\nWhen performing data analysis, it is always important to define a question that you seek the answer to. *The goal of finding the answer to this question will ultimately drive the queries and analysis styles you choose to use/write.*\n\nFor this example, we are going to ask: **where have [*Argia agrioides*](https://www.google.com/search?q=Argia+agrioides&rlz=1C1CHBF_enUS734US734&source=lnms&tbm=isch&sa=X&ved=0ahUKEwji9t29kNTWAhVBymMKHWJ-ANcQ_AUICygC&biw=1536&bih=694) (the California Dancer dragonfly) been documented? Are there records at any of our field stations?**\n\nThe code to ask the API has already been written for us! This is often the case with programming, someone has already written the code, so we don't have to. We'll just set up the `GBIFRequest` object and assign that to the variable `req`, short for \"request\":","metadata":{}},{"cell_type":"code","source":"req = GBIFRequest()  # creating a request to the API","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Great, so how do we make searches? We can use a Python `dictionary` to create our query parameters. We'll ask for the `scientificName` of the California Dancer (*Argia arioides*):","metadata":{}},{"cell_type":"code","source":"params = {'scientificName': 'Argia agrioides'}  # setting our parameters (the specific species we want)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now that we have the parameters, we can feed this to our `req` variable to get back all the pages of data. We'll then make sure that each record has a `decimalLatitude`, otherwise we'll thow it out for now. Lastly, we'll print out the first five records:","metadata":{}},{"cell_type":"code","source":"params = {'scientificName': 'Argia agrioides'}  # setting our parameters (the specific species we want)\npages = req.get_pages(params)  # using those parameters to complete the request\nrecords = [rec for page in pages for rec in page['results'] if rec.get('decimalLatitude')]  # sift out valid records\n# records[:5]  # print first 5 records","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### DataFrames\n\nJSON is great, but it might be conceptually easier to make this a table. We'll use the popular [`pandas`](http://pandas.pydata.org/) Python library. In `pandas`, a DataFrame is a table that has several convenient features. For example, we can access the columns of the table like we would `dict`ionaries, and we can also treat the columns and rows themselves as Python `list`s.","metadata":{}},{"cell_type":"code","source":"records_df = pd.DataFrame(records)   # converts the JSON above to a dataframe\nrecords_df.head()  # prints the first five rows of the dataframe","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"QUESTION: why are there so many columns called ```key```? What would they be used for? Scroll to the right. What does ```NaN``` stand for?\n\nSince each column (or row) above can be thought of as a `list`, that means we can use list functions to interact with them! One such function is the `len` function to get the number of elements in a `list`:","metadata":{}},{"cell_type":"code","source":"len(records_df.columns), len(records_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"How many columns are there? (hint: look at the first result term) How many records/rows? (hint: it's the other value)! That's a lot of information. What variables do we have in the columns?","metadata":{}},{"cell_type":"code","source":"records_df.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can use two methods from `pandas` to do a lot more. The `value_counts()` method will tabulate the frequency of the row value in a column, and the `plot.barh()` will plot us a horizontal bar chart:","metadata":{}},{"cell_type":"code","source":"records_df['country'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"records_df['country'].value_counts().plot.barh()\nplot.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"records_df['basisOfRecord'].value_counts().plot.barh()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"records_df['institutionCode'].value_counts().plot.barh()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The `groupby()` method allows us to count based one column based on another, and then color the bar chart differently depending on a variable of our choice:","metadata":{}},{"cell_type":"code","source":"records_df.groupby([\"collectionCode\", \"basisOfRecord\"])['basisOfRecord'].count()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"records_df.groupby([\"collectionCode\", \"basisOfRecord\"])['basisOfRecord'].count().unstack().plot.barh(stacked=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"And we can use `plot.hist()` to make a histogram:","metadata":{}},{"cell_type":"code","source":"records_df['elevation'].plot.hist()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n<div class=\"alert alert-info\">\n**Exercise**: Edit the code below to search for a different species you're interested in, then adapt some of the graphing cells above to explore your data!\n</div>","metadata":{}},{"cell_type":"code","source":"my_req = GBIFRequest()  # creating a request to the API\nmy_params = {'scientificName': 'Taricha rivularis'}  # setting our parameters (the specific species we want)\nmy_pages = my_req.get_pages(my_params)  # using those parameters to complete the request\nmy_records = [rec for page in my_pages for rec in page['results'] if rec.get('decimalLatitude')]  # sift out valid records\nmy_records_df = pd.DataFrame(my_records)  # make a dataframe\nmy_records_df.tail()  # print last 5 rows","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"my_records_df['year'].plot.hist()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n### Mapping\n\nNow we can map our latitude and longitude points. We'll want to color code by `collectionCode` so we can see which collection made the observation or has the specimen. We'll use a function that does this automatically, but it will randomly generate a color, so if you get a lot of a similar color maybe run the cell a couple times!","metadata":{}},{"cell_type":"code","source":"color_dict, html_key = assign_colors(records_df, \"institutionCode\")\ndisplay(HTML(html_key))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"legend_html = \"\"\"\n<div style='background-color: white; padding: 15px; border-radius: 8px; \n            border: 2px solid #ddd; max-width: 400px; font-family: Arial, sans-serif;'>\n    <h3 style='margin-top: 0; color: #333; font-size: 16px;'>Legend</h3>\n    <div style='display: flex; flex-direction: column; gap: 8px;'>\n\"\"\"\n\nfor species, color in color_dict.items():\n    legend_html += f\"\"\"\n        <div style='display: flex; align-items: center; gap: 10px;'>\n            <div style='width: 30px; height: 20px; background-color: {color}; \n                        border: 1px solid #333; border-radius: 3px;'></div>\n            <span style='color: #333; font-size: 14px;'>{species}</span>\n        </div>\n    \"\"\"\n\nlegend_html += \"\"\"\n    </div>\n</div>\n\"\"\"\n\ndisplay(HTML(legend_html))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we can map the points!","metadata":{}},{"cell_type":"code","source":"mapa = folium.Map(location=[37.359276, -122.179626], zoom_start=5) # Folium is a useful library for generating\n                                                                   # Google maps-like map visualizations.\nfor r in records_df.iterrows():\n    lat = r[1]['decimalLatitude']\n    long = r[1]['decimalLongitude']\n    folium.CircleMarker((lat, long), color=color_dict[r[1]['institutionCode']], popup=r[1]['basisOfRecord']).add_to(mapa)\nmapa","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\nTo get the boundries for all the reserves, we will need to send a request to get GeoJSON, which is a format for encoding a variety of geographic data structures. With this code, we can request GeoJSON for all reserves and plot ocurrences of the species. First we'll assign the API URL that has the data to a new variable `url`:","metadata":{}},{"cell_type":"markdown","source":"Now we make the requests just like we did earlier through the GBIF:","metadata":{}},{"cell_type":"code","source":"url = 'https://raw.githubusercontent.com/ds-modules/IB-ESPM-105/refs/heads/master/ecoengine.berkeley.edu.json'\n\ntimeout_value = 10  # Set the timeout value\nmax_retries = 3  # Number of retries","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reserves = requests.get(url, params={'page_size': 30}).json()\nreserves","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"If you look closely, this is just bounding boxes for the latitude and longitude of the reserves.\n\nThere are some reserves that the EcoEngine didn't catch, we'll add the information for \"Blodgett\", \"Hopland\", and \"Sagehen\":","metadata":{}},{"cell_type":"code","source":"station_urls = {\n    'Blodgett': 'https://raw.githubusercontent.com/BNHM/spatial-layers/master/wkt/BlodgettForestResearchStation.wkt',\n    'Hopland': 'https://raw.githubusercontent.com/BNHM/spatial-layers/master/wkt/HoplandResearchAndExtensionCenter.wkt',\n    'Sagehen': 'https://raw.githubusercontent.com/BNHM/spatial-layers/master/wkt/SagehenCreekFieldStation.wkt',\n    'Blue Oak Ranch Reserve': 'https://raw.githubusercontent.com/BNHM/spatial-layers/master/wkt/BlueOakRanchReserve.wkt'\n}\n","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"[r['properties']['name'] for r in reserves['features']]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can send this `geojson` directly to our mapping library `folium`. You'll have to zoom in, but you should see blue outlines areas, there are the reserves!:","metadata":{}},{"cell_type":"code","source":"mapb = folium.Map(location=[37.359276, -122.179626], zoom_start=5) \n\nwkt = folium.features.GeoJson(reserves)\nmapb.add_child(wkt)\nfor r in records_df.iterrows():\n    lat = r[1]['decimalLatitude']\n    long = r[1]['decimalLongitude']\n    folium.CircleMarker((lat, long), color=color_dict[r[1]['institutionCode']], popup=r[1]['basisOfRecord']).add_to(mapb)\nmapb","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n<div class=\"alert alert-info\">\n**Exercise**: Edit the code below where you see `...` to map your selection for `scientificName` from `my_records_df` (PS. no need to add single quotes)\n</div>","metadata":{}},{"cell_type":"code","source":"my_req = GBIFRequest()  # creating a request to the API\nmy_params = {'scientificName': '...'}  # setting parameters (the specific species)\nmy_pages = my_req.get_pages(my_params)  # using those parameters to complete the request\nmy_records = [rec for page in my_pages for rec in page['results'] if rec.get('decimalLatitude')]  # sift out valid records\nmy_records_df = pd.DataFrame(my_records)  # make a dataframe\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"color_dict, html_key = assign_colors(my_records_df, \"institutionCode\")\ndisplay(HTML(html_key))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mapc = folium.Map([37.359276, -122.179626], zoom_start=5)\n\npoints = folium.features.GeoJson(reserves)\nmapc.add_child(points)\nfor r in my_records_df.iterrows():\n    lat = r[1]['decimalLatitude']\n    long = r[1]['decimalLongitude']\n    folium.CircleMarker((lat, long), color=color_dict[r[1]['institutionCode']]).add_to(mapc)\nmapc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\nWe can also find out which stations have how many *Argia argrioides*. First we'll have to add a column to our `DataFrame` that makes points out of the latitude and longitude coordinates:","metadata":{}},{"cell_type":"code","source":"def make_point(row):\n    return Point(row['decimalLongitude'], row['decimalLatitude'])\n\nrecords_df[\"point\"] = records_df.apply(lambda row: make_point (row),axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we can write a little function to check whether that point is in one of the stations, and if it is, we'll add that station in a new column called `station`:","metadata":{}},{"cell_type":"code","source":"def in_station(reserves, row):\n    \n    reserve_polygons = []\n\n    for r in reserves['features']:\n        name = r['properties']['name']\n        poly = sg.shape(r['geometry'])\n        reserve_polygons.append({\"id\": name,\n                                 \"geometry\": poly})\n    \n    sid = False\n    for r in reserve_polygons:\n        if r['geometry'].contains(row['point']):\n            sid = r['id']\n            sid = r['id']\n    if sid:\n        return sid\n    else:\n        return False","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now apply this function to the `DataFrame`:","metadata":{}},{"cell_type":"code","source":"records_df[\"station\"] = records_df.apply(lambda row: in_station(reserves, row),axis=1)\nin_stations_df = records_df[records_df[\"station\"] != False]\nin_stations_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's see if this corresponds to what we observed on the map:","metadata":{}},{"cell_type":"code","source":"in_stations_df.groupby([\"species\", \"station\"])['station'].count().unstack().plot.barh(stacked=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n# Part 3: Comparing California Oak species:<a id='oak'></a>\n\n\n| ![quercus douglassi](https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Large_Blue_Oak.jpg/220px-Large_Blue_Oak.jpg)  | ![quercus lobata](https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Valley_Oak_Mount_Diablo.jpg/220px-Valley_Oak_Mount_Diablo.jpg) | ![quercus durata](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b8/Quercusduratadurata.jpg/220px-Quercusduratadurata.jpg) | ![quercus agrifolia](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d1/Quercus_agrifolia_foliage.jpg/220px-Quercus_agrifolia_foliage.jpg) |\n|:---:|:---:|:---:|:---:|\n| *Quercus douglassi* | *Quercus lobata* | *Quercus durata* | *Quercus agrifolia*|\n\n\nLet's search for these different species of oak using our `GBIF` API and collect the observations:","metadata":{}},{"cell_type":"code","source":"species_records = []\n\nspecies = [\"Quercus douglassi\", \"Quercus lobata\", \"Quercus durata\", \"Quercus agrifolia\"]\n\nfor s in species:\n    req = GBIFRequest()  # creating a request to the API\n    params = {'scientificName': s}  # setting our parameters (the specific species we want)\n    pages = req.get_pages(params)  # using those parameters to complete the request\n    records = [rec for page in pages for rec in page['results'] if rec.get('decimalLatitude')]  # sift out valid records\n    species_records.extend(records)\n    time.sleep(3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can convert this JSON to a `DataFrame` again:","metadata":{}},{"cell_type":"code","source":"records_df = pd.DataFrame(species_records)\nrecords_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"How many records do we have now?","metadata":{}},{"cell_type":"code","source":"len(records_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's see how they're distributed among our different species queries:","metadata":{}},{"cell_type":"code","source":"records_df['species'].value_counts().plot.barh()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can group this again by `collectionCode`:","metadata":{}},{"cell_type":"code","source":"records_df.groupby([\"species\", \"collectionCode\"])['collectionCode'].count().unstack().plot.barh(stacked=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can also map these like we did with the *Argia arioides* above:","metadata":{}},{"cell_type":"code","source":"color_dict, html_key = assign_colors(records_df, \"species\")\ndisplay(HTML(html_key))","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"legend_html = \"\"\"\n<div style='background-color: white; padding: 15px; border-radius: 8px; \n            border: 2px solid #ddd; max-width: 400px; font-family: Arial, sans-serif;'>\n    <h3 style='margin-top: 0; color: #333; font-size: 16px;'>Species Legend</h3>\n    <div style='display: flex; flex-direction: column; gap: 8px;'>\n\"\"\"\n\nfor species, color in color_dict.items():\n    legend_html += f\"\"\"\n        <div style='display: flex; align-items: center; gap: 10px;'>\n            <div style='width: 30px; height: 20px; background-color: {color}; \n                        border: 1px solid #333; border-radius: 3px;'></div>\n            <span style='color: #333; font-size: 14px;'>{species}</span>\n        </div>\n    \"\"\"\n\nlegend_html += \"\"\"\n    </div>\n</div>\n\"\"\"\n\ndisplay(HTML(legend_html))","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mapc = folium.Map([37.359276, -122.179626], zoom_start=5)\n \n\nfor r in records_df.iterrows():\n    lat = r[1]['decimalLatitude']\n    long = r[1]['decimalLongitude']\n    folium.CircleMarker((lat, long), color=color_dict[r[1]['species']]).add_to(mapc)\nmapc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can use the same code we wrote earlier to see which reserves have which species of oak:","metadata":{}},{"cell_type":"code","source":"records_df[\"point\"] = records_df.apply(lambda row: make_point (row),axis=1)\nrecords_df[\"station\"] = records_df.apply(lambda row: in_station(reserves, row),axis=1)\nin_stations_df = records_df[records_df[\"station\"] != False]\nin_stations_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we can make a bar graph like we did before, grouping by `species` and stacking the bar based on `station`:","metadata":{}},{"cell_type":"code","source":"in_stations_df.groupby([\"species\", \"station\"])['station'].count().unstack().plot.barh(stacked=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"---\n\nWhat if we look specifically at the field stations and reserves? Can we integrate other environmental datasets based on spatial coordinates? We can grab our same code that checked whether a record was within a station, and then map those `gbifID`s back to other downloaded datasets. If there is time, this can be done in Part 4 of this exercise which is a separate Jupyter Notebook.","metadata":{}},{"cell_type":"markdown","source":"What does this example of accessing data from museums suggest to you about using data about endangered species? About considering observations from protected areas? Or about assessing climate change impact or refuges for species like *Argia agrioides*? ","metadata":{}},{"cell_type":"raw","source":"","metadata":{}}]}